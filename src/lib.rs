//! An implementation of SipHash.

#![cfg_attr(not(test), no_std)]

#[cfg(test)]
mod tests;

use core::mem::transmute;
use core::ptr;

#[inline(always)]
fn wadd(a: &mut u64, b: u64) {
    *a = a.wrapping_add(b);
}

#[inline(always)]
fn rotl(a: &mut u64, b: u32) {
    *a = a.rotate_left(b);
}

#[rustfmt::skip]
macro_rules! sip_round {
    ($a:ident, $b:ident, $c:ident, $d:ident) => {{
        wadd(&mut $a, $b); rotl(&mut $b, 13); $b ^= $a; rotl(&mut $a, 32);
        wadd(&mut $c, $d); rotl(&mut $d, 16); $d ^= $c;
        wadd(&mut $a, $d); rotl(&mut $d, 21); $d ^= $a;
        wadd(&mut $c, $b); rotl(&mut $b, 17); $b ^= $c; rotl(&mut $c, 32);
    }};
}

pub fn siphash24(bytes: &[u8], (key0, key1): (u64, u64)) -> u64 {
    let mut v0 = key0 ^ 0x736f_6d65_7073_6575_u64;
    let mut v1 = key1 ^ 0x646f_7261_6e64_6f6d_u64;
    let mut v2 = key0 ^ 0x6c79_6765_6e65_7261_u64;
    let mut v3 = key1 ^ 0x7465_6462_7974_6573_u64;

    let mut s = &bytes[..];

    while s.len() >= 8 {
        // We could just transmute here but using `copy_nonoverlapping`
        // with `dest` as u64 to keep reading to `m` as 8 alignment.
        // Also to avoid `memcpy` call which maybe slow in small byte size.
        let mut m = 0u64;
        unsafe {
            ptr::copy_nonoverlapping(s.as_ptr(), (&mut m as *mut u64).cast(), 8);
        }
        m.to_le();
        v3 ^= m;
        sip_round!(v0, v1, v2, v3);
        sip_round!(v0, v1, v2, v3);
        v0 ^= m;
        s = &s[8..];
    }

    // The implementation below using `copy_nonoverlapping` to avoid `memcpy` call
    // generated by the compiler. It also has the fast startup time for small result
    // (14ns) and has smaller code size (167 x86_64 ASM lines).
    //
    // Godbolt: <https://rust.godbolt.org/z/Er3voM>.
    let m: u64 = unsafe {
        let mut m = (bytes.len() as u64) << 56;
        let len = s.len();
        debug_assert!(len < 8);
        let mut i = 0; // current byte index (from LSB) in the output u64
        if i + 3 < len {
            let mut data = 0u32;
            ptr::copy_nonoverlapping(s.as_ptr().add(i), (&mut data as *mut u32).cast(), 4);
            m |= data.to_le() as u64;
            i += 4;
        }
        if i + 1 < len {
            let mut data = 0u16;
            ptr::copy_nonoverlapping(s.as_ptr().add(i), (&mut data as *mut u16).cast(), 2);
            m |= (data.to_le() as u64) << (8 * i);
            i += 2;
        }
        if i < len {
            m |= (s[i] as u64) << (8 * i);
            i += 1;
        }
        debug_assert_eq!(i, len);
        u64::to_le(transmute(m))
    };
    v3 ^= m;
    sip_round!(v0, v1, v2, v3);
    sip_round!(v0, v1, v2, v3);
    v0 ^= m;

    v2 ^= 0xff;
    sip_round!(v0, v1, v2, v3);
    sip_round!(v0, v1, v2, v3);
    sip_round!(v0, v1, v2, v3);
    sip_round!(v0, v1, v2, v3);
    v0 ^ v1 ^ v2 ^ v3
}
